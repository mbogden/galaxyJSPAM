{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "engaged-press",
   "metadata": {},
   "source": [
    "# Working Notebook for creating wndchrm features\n",
    "\n",
    "## Step 1\n",
    "### Load nessecary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "twelve-light",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIMR: Hi!  You're in Matthew's main program for all things galaxy collisions\n",
      "GM: Hi!  You're in Matthew's module for generally useful functions and classes\n",
      "IM: Hi!  You're in Matthew's information module for SPAM\n",
      "IC: Hi!  You're in Matthew's main code for all things image creation.\n",
      "FE: Hi!  You're in Matthew's module for extracting feature values from images.\n",
      "MS: Hi!  You're in Matthew's SIMR module for all things machine scoring images\n",
      "DC: Hi!  You're in direct_image_compare.py\n",
      "SA: Hi!  You're in Matthew's Main program for score analysis!\n"
     ]
    }
   ],
   "source": [
    "# Add python modules\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "\n",
    "# Add parent directory for custom modules\n",
    "from sys import path as sysPath\n",
    "sysPath.append('../')\n",
    "sysPath.append('../Machine_Score/')\n",
    "\n",
    "# Load custom modules that simr has loaded\n",
    "import main_SIMR as simr\n",
    "gm = simr.gm\n",
    "im = simr.im\n",
    "ic = simr.ic\n",
    "fe = simr.fe\n",
    "ms = simr.ms\n",
    "sa = simr.sa\n",
    "dc = simr.ms.dc\n",
    "\n",
    "simr.test()\n",
    "gm.test()\n",
    "im.test()\n",
    "ic.test()\n",
    "fe.test()\n",
    "ms.test()\n",
    "dc.test()\n",
    "sa.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perfect-mortgage",
   "metadata": {},
   "source": [
    "___\n",
    "## Step 2\n",
    "### Load Target Info class\n",
    "Needed for loading the target image and running through models later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "union-binding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Good!: 587722984435351614\n",
      "Run Good!: run_0000\n"
     ]
    }
   ],
   "source": [
    "tDir = '../targetDir'\n",
    "tDir = gm.validPath(tDir)\n",
    "\n",
    "tInfo = im.target_info_class( targetDir = tDir, printAll=False)\n",
    "if tInfo.status == False:\n",
    "    print(\"WARNING: target info class bad\")\n",
    "else:\n",
    "    print(\"Target Good!: %s\" % tInfo.get('target_id'))\n",
    "\n",
    "# Get run info class\n",
    "rInfo = tInfo.getRunInfo( rID='run_0000' )\n",
    "\n",
    "if rInfo.status == False:\n",
    "    print(\"WARNING\")\n",
    "else:\n",
    "    print(\"Run Good!: %s\"%rInfo.get('run_id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "commercial-tunnel",
   "metadata": {},
   "source": [
    "___\n",
    "## Step 4: Create a new image parameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "parallel-tennessee",
   "metadata": {},
   "outputs": [],
   "source": [
    "chimeLoc = './../param/chime_group_1.json'\n",
    "chime_group_1 = gm.readJson( chimeLoc )\n",
    "#gm.pprint(chime_group_1['chime_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "mechanical-helen",
   "metadata": {},
   "outputs": [],
   "source": [
    "testArg = gm.inArgClass()\n",
    "testArg.printAll = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "north-enemy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FE: target_collect_wndchrm_all_raw\n",
      "FE: target_collect_wndchrm_all_raw: Loop: 1293 / 1293: Complete!\n",
      "\t - Read 1290 of 1293 wndchrm run files.\n",
      "\t - Final WNDCHRM DataFrame\n",
      "\t - Shape: (61921, 1062)\n",
      "\t - Unique Runs: 1290\n",
      "\t - Unique Image Names: 49\n",
      "\t - Header Length: 1062\n",
      "\t - Headers head: [ run_id, image_name, zoo_merger_score, ... ]\n",
      "\t - Headers tail: [ ... , Zernike Coefficients (Fourier ()) [70], Zernike Coefficients (Fourier ()) [71] ]\n"
     ]
    }
   ],
   "source": [
    "fe.target_collect_wndchrm_all_raw( testArg, tInfo = tInfo )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "commercial-subsection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read\n"
     ]
    }
   ],
   "source": [
    "runsRaw = pd.read_pickle( tInfo.wndRunRawLoc )\n",
    "targetRaw = pd.read_csv( tInfo.wndTargetRawLoc )\n",
    "print(\"read\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "extreme-christian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FE: normalize_target_wnchrm.\n",
      "\t - tID: 587722984435351614\n",
      "\t - Normalization Parameters\n",
      "{'image_group': 'chime_group_1',\n",
      " 'name': 'norm_wndchrm_test',\n",
      " 'normalization_method': 'sklearn_StandardScaler',\n",
      " 'top_models': 500}\n",
      "\t - Target Shape: (1, 1062)\n",
      "\t - Runs Shape: (61921, 1062)\n",
      "\t - All Raw Shape: (61922, 1063)\n",
      "\t - top_models: 500\n",
      "\t - Shape top N: (24002, 1063)\n",
      "\t - Shape image group: (24001, 1063)\n",
      "\t - All Raw Shape: (24001, 1063)\n",
      "\t - filtered out: (24000, 1063)\n",
      "\t - info Headers: [ run_id, target_id, image_name, zoo_merger_score ]\n",
      "\t - feat value Shape: (24000, 1059)\n",
      "\t - Creating Scaler: sklearn_StandardScaler\n",
      "\t - Scaler Complete. Saving...\n",
      "\t - Applying scaler to all data\n",
      "\t - Raw Feat Values Shape: (61922, 1059)\n",
      "\t - Transforming Raw Feat Values...\n",
      "\t - Transform Complete\n",
      "\t - Scaled Feat Values Shape: (61922, 1059)\n",
      "\t - Scaled Info Values Shape: (61922, 4)\n",
      "\t - Scaled DF Shape: (61922, 1063)\n",
      "\t - Saving scaled DF...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to collect model wndchrm values and normalize them.\n",
    "def target_wndchrm_create_norm_scaler( args, tInfo, normDict, groupParam = None ):\n",
    "    \n",
    "    printAll = args.printAll\n",
    "    printBase = args.printBase\n",
    "    \n",
    "    if printBase:\n",
    "        print( \"FE: normalize_target_wnchrm.\" )\n",
    "        gm.tabprint( \"tID: %s\" % tInfo.get( 'target_id' ) )\n",
    "        gm.tabprint( \"Normalization Parameters\")\n",
    "        gm.pprint( normDict )\n",
    "        \n",
    "    # Useful variables\n",
    "    \n",
    "    infoHeaders = [ 'run_id', 'target_id', 'image_name', 'zoo_merger_score' ]\n",
    "        \n",
    "    # Remove quotes later\n",
    "    '''\n",
    "    target_collect_wndchrm_all_raw( args, tInfo )\n",
    "    runsRaw = pd.read_csv( tInfo.wndRunRawLoc )\n",
    "    targetRaw = pd.read_csv( tInfo.wndTargetRawLoc )\n",
    "    '''\n",
    "    \n",
    "    allRawDF = pd.concat( [ runsRaw, targetRaw ] )\n",
    "    allInfoDF = allRawDF[ infoHeaders ]\n",
    "    \n",
    "    if printAll:\n",
    "        gm.tabprint( 'Target Shape: %s' % str( targetRaw.shape ) )\n",
    "        gm.tabprint( 'Runs Shape: %s' % str( runsRaw.shape ) )\n",
    "        gm.tabprint( 'All Raw Shape: %s' % str( allRawDF.shape ) )\n",
    "    \n",
    "    \n",
    "    # Combine top N models and target \n",
    "    if normDict.get( 'top_models', None) != None:\n",
    "        \n",
    "        topN = int( normDict['top_models'] )\n",
    "        \n",
    "        if printAll:\n",
    "            gm.tabprint( 'top_models: %d' % topN )\n",
    "        \n",
    "        # Grab names of top N models\n",
    "        # assume run_id is listed in alphanumerical order of best.  This will likely change later\n",
    "        runIDList = list(runsRaw['run_id'].unique())[0:topN]        \n",
    "        topRunRaw = runsRaw[ runsRaw['run_id'].isin(runIDList) ]        \n",
    "        trainDF = pd.concat( [ topRunRaw, targetRaw ] )\n",
    "        \n",
    "        if printAll: gm.tabprint(\"Shape top N: %s\" % str( trainDF.shape ) )\n",
    "    \n",
    "    # Combine all models and target.\n",
    "    else:\n",
    "        trainDF = pd.concat( [ runsRaw, targetRaw ] )\n",
    "         \n",
    "    \n",
    "    # Extract only images from image_group\n",
    "    if groupParam != None:\n",
    "        imgNameList = [ groupParam[pKey]['imgArg']['name'] for pKey in groupParam ]\n",
    "        trainDF = trainDF[ trainDF['image_name'].isin(imgNameList) ]\n",
    "        \n",
    "        if printAll:    gm.tabprint(\"Shape image group: %s\" % str( trainDF.shape ) )\n",
    "    \n",
    "    if printAll:    gm.tabprint('All Raw Shape: %s'%str(trainDF.shape))\n",
    "    \n",
    "    # Headers not in info headers are assumed feature value header names\n",
    "    featHeaders = [ h for h in trainDF if h not in infoHeaders ]\n",
    "\n",
    "    # Remove any rows with nan values in feature headers\n",
    "    trainDF = trainDF[ ~trainDF[ featHeaders ].isin([np.nan, np.inf, -np.inf]).any(1)]\n",
    "    if printAll:    gm.tabprint('filtered out: %s' % str(trainDF.shape))\n",
    "        \n",
    "    # Seperate information columns from feature value columns being normalized.\n",
    "    trainRaw = trainDF.drop( infoHeaders, axis=1 ).values\n",
    "    \n",
    "    if printAll:\n",
    "        gm.tabprint('info Headers: [ %s ]' % ', '.join(infoHeaders))\n",
    "        gm.tabprint('feat value Shape: %s' % str(trainRaw.shape ) )\n",
    "    \n",
    "    # Determine what method to use for normalizing data and create a scaler model\n",
    "    normMethod = normDict.get( 'normalization_method', 'sklearn_StandardScaler' )\n",
    "    \n",
    "    if printAll:    gm.tabprint(\"Creating Scaler: %s\" % normMethod )\n",
    "        \n",
    "    if normMethod == 'sklearn_StandardScaler':\n",
    "        from sklearn.preprocessing import StandardScaler \n",
    "        scaler = StandardScaler()\n",
    "        featScaled = scaler.fit_transform( trainRaw )\n",
    "    \n",
    "    else:\n",
    "        print(\"WARNING: FE: normalize_target_wndchrm\")\n",
    "        gm.tabprint(\"Normalization Method Not Found: %s\" % normMethod )\n",
    "        return\n",
    "    \n",
    "    if printAll:    gm.tabprint(\"Scaler Complete. Saving...\")\n",
    "\n",
    "    # Have target info save scaler file\n",
    "    tInfo.saveWndchrmScaler( scaler, normDict.get('name', 'default') )\n",
    "    \n",
    "    \n",
    "    # Apply new scaler to all the feature data      \n",
    "    if printAll: gm.tabprint(\"Applying scaler to all data\")    \n",
    "        \n",
    "    featRawValues = allRawDF.drop( infoHeaders, axis=1 ).values  \n",
    "    \n",
    "    if printAll: \n",
    "        gm.tabprint(\"Raw Feat Values Shape: %s\" % str( featRawValues.shape ) )\n",
    "        gm.tabprint(\"Transforming Raw Feat Values...\" )\n",
    "    \n",
    "    featScaledValues = scaler.transform( featRawValues )\n",
    "    \n",
    "    if printAll: \n",
    "        gm.tabprint(\"Transform Complete\" )\n",
    "        \n",
    "    \n",
    "    scaledDF = pd.DataFrame( featScaledValues, columns = featHeaders )\n",
    "    \n",
    "    #pd.concat([df1, df4.reindex(df1.index)], axis=1)\n",
    "    \n",
    "    if printAll: \n",
    "        gm.tabprint(\"Scaled Feat Values Shape: %s\" % str( scaledDF.shape ))\n",
    "        gm.tabprint(\"Scaled Info Values Shape: %s\" % str( allInfoDF.shape ))\n",
    "    \n",
    "    # In\n",
    "    for i,h in enumerate( infoHeaders ):\n",
    "        scaledDF.insert(i, h, allInfoDF[h].values )\n",
    "    \n",
    "    if printAll: \n",
    "        gm.tabprint(\"Scaled DF Shape: %s\" % str( scaledDF.shape ))\n",
    "        gm.tabprint(\"Saving scaled DF...\")\n",
    "    \n",
    "    tInfo.saveWndchrmDF( scaledDF, normDict['name'] )\n",
    "               \n",
    "# Have Target collect wndchrm values and collect into one file\n",
    "\n",
    "norm_wndchrm_all_test = {}\n",
    "norm_wndchrm_all_test['name'] = 'norm_wndchrm_test'\n",
    "norm_wndchrm_all_test['top_models'] = 500\n",
    "norm_wndchrm_all_test['image_group'] = 'chime_group_1'\n",
    "norm_wndchrm_all_test['normalization_method'] = 'sklearn_StandardScaler'\n",
    "\n",
    "normLoc = '../param/' + norm_wndchrm_all_test['name'] + '.json'\n",
    "gm.saveJson( norm_wndchrm_all_test, normLoc )\n",
    "#gm.pprint( norm_wndchrm_all_test )\n",
    "\n",
    "tArg = gm.inArgClass()\n",
    "tArg.printAll = True\n",
    "\n",
    "target_wndchrm_create_norm_scaler( tArg, tInfo, norm_wndchrm_all_test, groupParam = chime_group_1 )\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "small-zealand",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t - Collecting wndchrm all data\n"
     ]
    }
   ],
   "source": [
    "fe.wndchrm_target_all( gm.inArgClass(), tInfo )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "federal-graphic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "selective-simulation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IM: Target.gatherRunInfos\n",
      "\t - IM: gather_run_info LOOP: 1293 / 1293 COMPLETE\n",
      "IM: Target.saveInfoFile():\n",
      "\t - Saving target info file...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "tInfo.printAll = True\n",
    "tInfo.gatherRunInfos()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-jersey",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
